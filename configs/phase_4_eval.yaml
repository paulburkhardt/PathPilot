pipeline:
  components:
    # Load video data for SLAM processing
    - type: MAST3RSLAMVideoDataset
      config:
        video_path: evaluation/back_and_forth/back_and_forth.mp4
        mast3r_slam_config_path: "configs/MASt3R-SLAM_configs/no_calib.yaml"

    # Run the yolo segmenter
    - type: YOLOSegmenter
      config:
        model_path: "models/yolov8s-oiv7.pt"
        detection_interval: 1  # Run YOLO every 5 frames for performance
        conf_threshold: 0.4  # Confidence threshold for detections
        iou_threshold: 0.5    # IoU threshold for NMS
        max_detections: 20    # Maximum detections per image
    
    # Run SAM2 segmentation using YOLO bounding boxes as prompts
    - type: ImageDataSegmenter
      config:
        model_cfg_path: "sam2.1/sam2.1_hiera_t.yaml"
        checkpoint_path: "segment_anything_2/checkpoints/sam2.1_hiera_tiny.pt"
        detection_interval: 1    # Use YOLO detections every 5 frames (matches YOLO interval)
        min_mask_region_area: 200  # Minimum area for valid masks
        save_debug_images: false  # Enable debug image saving
        debug_output_dir: "debug_phase2_segmentation"  # Directory for debug images


    # Run MAST3R SLAM to generate point cloud and trajectory incrementally
    - type: MAST3RSLAMComponent
      config:
        point_cloud_method: accumulating
        c_confidence_threshold: 1.5 
        mast3r_slam_config_path: "configs/MASt3R-SLAM_configs/no_calib.yaml"
        segment_point_cloud: True
        only_keyframes: False 
    
    - type: PointCloudFilterSegmenter
      config:
        downsample_rate : 2
        min_cluster_size: 500
        neighbor_distance:  0.05
        ignore_backround: False 

    - type: ImageEmbeddingSegmenter
      config:
        text: "Describe the object: " # the prompt to generat


    - type: BBoxObjectDatabase
      config: 
        match_threshold : 0.4  # the higher the more matching happens
        embedding_weight : 0.4 # interpolation weight between geometric distance and similar. Higher value means similarity is more important
        running_embedding_weight  :  0.7 # how the running embedding get updated. higher value -> gets lets changed by new similar image
        knn_count  :  4 # controls how many options there are 
        use_blip  :  True # look if images are similar
        use_fusion  :  True # to join existing objects if needed # implemented but not tested for a while
        enable_same_mask_tracking : False # leave at false. this is for yolo and accumulating mode of Mast3r-slam important
        track_points: True # the pointclouds are actually not needed, but for nice visualisation i intregated it

    # Incremental floor detection - waits for 3 frames, refines frequently for better accuracy
    - type: IncrementalFloorDetectionComponent
      config:
        min_frames: 3  # Wait for 3 frames before starting
        sample_ratio: 0.15  # Slightly more points for better accuracy
        ransac_threshold: 0.05
        min_inliers: 1000
        floor_threshold: 0.05
        refine_interval: 10  # Refine every 10 frames for better accuracy
        max_refinement_poses: 30  # Use last 30 poses for refinement
    
    # Find closest points incrementally - waits for floor detection
    - type: IncrementalClosestPointFinderComponent
      config:
        use_view_cone: False  # Set to true to enable view cone filtering
        cone_angle_deg: 45.0
        use_segmentation_filter: False  # Enable filtering based on segmentation masks
        use_object_segmentation_filter: True # either use_segmentation_filter or use_object_segmentation_filter
        use_centroids: False 
        n_closest_points: 4  # Number of closest points to return #this is not needed for use_object_segmentation_filter
    # Enhanced output writer with intermediate saving enabled

    - type: EnhancedSLAMOutputWriter
      config:
        output_dir: "enhanced_slam_outputs"
        output_name: "incremental_analysis_detailed"
        save_point_cloud: true
        save_trajectory: true
        save_floor_data: true
        save_closest_points: true
        save_yolo_detections: true  # Save YOLO detection results
        save_intermediate: true  # Save intermediate results
        intermediate_interval: 10   # Save intermediate results every 5 frames
        create_timestamped_dir: true
        analysis_format: "csv"  # Can be "json" or "csv" 
        save_closest_points_segment_ids: true  # Save segment IDs for closest points 